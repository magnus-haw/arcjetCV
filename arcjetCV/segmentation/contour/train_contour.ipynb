{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# os.environ['TORCH_HOME'] = '/nobackup2/fsemerar/.cache/torch'\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/nobackup2/fsemerar/arcjetCV_stuff/arcjet_dataset'\n",
    "N_CLASSES = 4 \n",
    "MODEL_TYPE = \"xception\"\n",
    "\n",
    "IMAGE_PATH = os.path.join(ROOT_PATH, \"images\")\n",
    "MASK_PATH = os.path.join(ROOT_PATH, \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df():\n",
    "    name = []\n",
    "    for dirname, _, filenames in os.walk(IMAGE_PATH):\n",
    "        for filename in filenames:\n",
    "            name.append(filename.split('.')[0])\n",
    "    \n",
    "    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))\n",
    "\n",
    "df = create_df()\n",
    "print('Total Images: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test = train_test_split(df['id'].values, test_size=0.1, random_state=19)\n",
    "X_train, X_val = train_test_split(X_trainval, test_size=0.15, random_state=19)\n",
    "\n",
    "print('Train Size   : ', len(X_train))\n",
    "print('Val Size     : ', len(X_val))\n",
    "print('Test Size    : ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(os.path.join(IMAGE_PATH, df['id'][10] + '.jpg'))\n",
    "mask = Image.open(os.path.join(MASK_PATH, df['id'][10] + '.png'))\n",
    "print('Image Size', np.asarray(img).shape)\n",
    "print('Mask Size', np.asarray(mask).shape)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.imshow(mask, alpha=0.6)\n",
    "plt.title('Picture with Mask Applied')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcjetDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_path, mask_path, X, mean=None, std=None, transform=None, patch=False, testing=False):\n",
    "        self.img_path = img_path\n",
    "        self.mask_path = mask_path\n",
    "        self.X = X\n",
    "        self.transform = transform\n",
    "        self.patches = True if (patch and not testing) else False\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.testing = testing\n",
    "        if not testing and (mean is None or std is None):\n",
    "            raise Exception(\"Need to have mean and std if not testing\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(os.path.join(self.img_path, self.X[idx] + '.jpg'))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(os.path.join(self.mask_path, self.X[idx] + '.png'), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            aug = self.transform(image=img, mask=mask)\n",
    "            img = Image.fromarray(aug['image'])\n",
    "            mask = aug['mask']\n",
    "        \n",
    "        if self.transform is None:\n",
    "            img = Image.fromarray(img)\n",
    "        \n",
    "        if not self.testing:\n",
    "            t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])\n",
    "            img = t(img)\n",
    "            \n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        \n",
    "        if self.patches:\n",
    "            img, mask = self.tiles(img, mask)\n",
    "            \n",
    "        return img, mask\n",
    "    \n",
    "    def tiles(self, img, mask):\n",
    "\n",
    "        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768) \n",
    "        img_patches  = img_patches.contiguous().view(3,-1, 512, 768) \n",
    "        img_patches = img_patches.permute(1,0,2,3)\n",
    "        \n",
    "        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)\n",
    "        mask_patches = mask_patches.contiguous().view(-1, 512, 768)\n",
    "        \n",
    "        return img_patches, mask_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "t_train = A.Compose([A.Resize(512, 512, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), A.VerticalFlip(), \n",
    "                     A.GridDistortion(p=0.2), A.RandomBrightnessContrast((0,0.5),(0,0.5)),\n",
    "                     A.GaussNoise()])\n",
    "\n",
    "t_val = A.Compose([A.Resize(512, 512, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(),\n",
    "                   A.GridDistortion(p=0.2)])\n",
    "\n",
    "#datasets\n",
    "train_set = ArcjetDataset(IMAGE_PATH, MASK_PATH, X_train, mean, std, t_train, patch=False)\n",
    "val_set = ArcjetDataset(IMAGE_PATH, MASK_PATH, X_val, mean, std, t_val, patch=False)\n",
    "\n",
    "#dataloader\n",
    "batch_size= 3 \n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(MODEL_TYPE, classes=N_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(output, mask):\n",
    "    with torch.no_grad():\n",
    "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
    "        correct = torch.eq(output, mask).int()\n",
    "        accuracy = float(correct.sum()) / float(correct.numel())\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=23):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(0, n_classes): #loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union +smooth)\n",
    "                iou_per_class.append(iou)\n",
    "        return np.nanmean(iou_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    val_iou = []; val_acc = []\n",
    "    train_iou = []; train_acc = []\n",
    "    lrs = []\n",
    "    min_loss = np.inf\n",
    "    decrease = 1 ; not_improve=0\n",
    "\n",
    "    model.to(device)\n",
    "    fit_time = time.time()\n",
    "    for e in range(epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0\n",
    "        iou_score = 0\n",
    "        accuracy = 0\n",
    "        #training loop\n",
    "        model.train()\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "            #training phase\n",
    "            image_tiles, mask_tiles = data\n",
    "            if patch:\n",
    "                bs, n_tiles, c, h, w = image_tiles.size()\n",
    "\n",
    "                image_tiles = image_tiles.view(-1,c, h, w)\n",
    "                mask_tiles = mask_tiles.view(-1, h, w)\n",
    "            \n",
    "            image = image_tiles.to(device); mask = mask_tiles.to(device);\n",
    "            #forward\n",
    "            output = model(image)\n",
    "            loss = criterion(output, mask)\n",
    "            #evaluation metrics\n",
    "            iou_score += mIoU(output, mask, n_classes=N_CLASSES)\n",
    "            accuracy += pixel_accuracy(output, mask)\n",
    "            #backward\n",
    "            loss.backward()\n",
    "            optimizer.step() #update weight          \n",
    "            optimizer.zero_grad() #reset gradient\n",
    "            \n",
    "            #step the learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            scheduler.step() \n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        else:\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            test_accuracy = 0\n",
    "            val_iou_score = 0\n",
    "            #validation loop\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(tqdm(val_loader)):\n",
    "                    #reshape to 9 patches from single image, delete batch size\n",
    "                    image_tiles, mask_tiles = data\n",
    "\n",
    "                    if patch:\n",
    "                        bs, n_tiles, c, h, w = image_tiles.size()\n",
    "\n",
    "                        image_tiles = image_tiles.view(-1,c, h, w)\n",
    "                        mask_tiles = mask_tiles.view(-1, h, w)\n",
    "                    \n",
    "                    image = image_tiles.to(device); mask = mask_tiles.to(device);\n",
    "                    output = model(image)\n",
    "                    #evaluation metrics\n",
    "                    val_iou_score +=  mIoU(output, mask)\n",
    "                    test_accuracy += pixel_accuracy(output, mask)\n",
    "                    #loss\n",
    "                    loss = criterion(output, mask)                                  \n",
    "                    test_loss += loss.item()\n",
    "            \n",
    "            #calculatio mean for each batch\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(val_loader))\n",
    "\n",
    "\n",
    "            if min_loss > (test_loss/len(val_loader)):\n",
    "                print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))\n",
    "                min_loss = (test_loss/len(val_loader))\n",
    "                decrease += 1\n",
    "                if decrease % 5 == 0:\n",
    "                    print('saving model...')\n",
    "                    torch.save(model, f'Unet-{MODEL_TYPE}_mIoU-{:.3f}.pt'.format(val_iou_score/len(val_loader)))\n",
    "                    \n",
    "\n",
    "            if (test_loss/len(val_loader)) > min_loss:\n",
    "                not_improve += 1\n",
    "                min_loss = (test_loss/len(val_loader))\n",
    "                print(f'Loss Not Decrease for {not_improve} time')\n",
    "                if not_improve == 7:\n",
    "                    print('Loss not decrease for 7 times, Stop Training')\n",
    "                    break\n",
    "            \n",
    "            #iou\n",
    "            val_iou.append(val_iou_score/len(val_loader))\n",
    "            train_iou.append(iou_score/len(train_loader))\n",
    "            train_acc.append(accuracy/len(train_loader))\n",
    "            val_acc.append(test_accuracy/ len(val_loader))\n",
    "            print(\"Epoch:{}/{}..\".format(e+1, epochs),\n",
    "                  \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n",
    "                  \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n",
    "                  \"Train mIoU:{:.3f}..\".format(iou_score/len(train_loader)),\n",
    "                  \"Val mIoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n",
    "                  \"Train Acc:{:.3f}..\".format(accuracy/len(train_loader)),\n",
    "                  \"Val Acc:{:.3f}..\".format(test_accuracy/len(val_loader)),\n",
    "                  \"Time: {:.2f}m\".format((time.time()-since)/60))\n",
    "        \n",
    "    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n",
    "               'train_miou' :train_iou, 'val_miou':val_iou,\n",
    "               'train_acc' :train_acc, 'val_acc':val_acc,\n",
    "               'lrs': lrs}\n",
    "    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_lr = 1e-3\n",
    "epoch = 15\n",
    "weight_decay = 1e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n",
    "                                            steps_per_epoch=len(train_loader))\n",
    "\n",
    "history = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'Unet-{MODEL_TYPE}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history['val_loss'], label='val', marker='o')\n",
    "    plt.plot( history['train_loss'], label='train', marker='o')\n",
    "    plt.title('Loss per epoch'); plt.ylabel('loss');\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(), plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_score(history):\n",
    "    plt.plot(history['train_miou'], label='train_mIoU', marker='*')\n",
    "    plt.plot(history['val_miou'], label='val_mIoU',  marker='*')\n",
    "    plt.title('Score per epoch'); plt.ylabel('mean IoU')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(), plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_acc(history):\n",
    "    plt.plot(history['train_acc'], label='train_accuracy', marker='*')\n",
    "    plt.plot(history['val_acc'], label='val_accuracy',  marker='*')\n",
    "    plt.title('Accuracy per epoch'); plt.ylabel('Accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(), plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)\n",
    "plot_score(history)\n",
    "plot_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = A.Resize(512, 512, interpolation=cv2.INTER_NEAREST)\n",
    "test_set = ArcjetDataset(IMAGE_PATH, MASK_PATH, X_test, transform=t_test, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f'Unet-{MODEL_TYPE}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_mask_miou(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], n_classes=23):\n",
    "    model.eval()\n",
    "    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
    "    image = t(image)\n",
    "    model.to(device) \n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        image = image.unsqueeze(0)\n",
    "        mask = mask.unsqueeze(0)\n",
    "        \n",
    "        output = model(image)\n",
    "        score = mIoU(output, mask, n_classes=n_classes)\n",
    "        masked = torch.argmax(output, dim=1)\n",
    "        masked = masked.cpu().squeeze(0)\n",
    "    return masked, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = test_set[1]\n",
    "pred_mask, score = predict_image_mask_miou(model, image, mask, n_classes=N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,10))\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Picture')\n",
    "\n",
    "ax2.imshow(mask)\n",
    "ax2.set_title('Ground truth')\n",
    "ax2.set_axis_off()\n",
    "\n",
    "ax3.imshow(pred_mask)\n",
    "ax3.set_title(f'UNet-{MODEL_TYPE} | mIoU {round(score, 3)}')\n",
    "ax3.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_mask_pixel(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "    model.eval()\n",
    "    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
    "    image = t(image)\n",
    "    model.to(device); image=image.to(device)\n",
    "    mask = mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        image = image.unsqueeze(0)\n",
    "        mask = mask.unsqueeze(0)\n",
    "        \n",
    "        output = model(image)\n",
    "        acc = pixel_accuracy(output, mask)\n",
    "        masked = torch.argmax(output, dim=1)\n",
    "        masked = masked.cpu().squeeze(0)\n",
    "    return masked, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miou_score(model, test_set):\n",
    "    score_iou = []\n",
    "    for i in tqdm(range(len(test_set))):\n",
    "        img, mask = test_set[i]\n",
    "        pred_mask, score = predict_image_mask_miou(model, img, mask)\n",
    "        score_iou.append(score)\n",
    "    return score_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_miou = miou_score(model, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_acc(model, test_set):\n",
    "    accuracy = []\n",
    "    for i in tqdm(range(len(test_set))):\n",
    "        img, mask = test_set[i]\n",
    "        pred_mask, acc = predict_image_mask_pixel(model, img, mask)\n",
    "        accuracy.append(acc)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_acc = pixel_acc(model, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Set mIoU', np.mean(mob_miou))\n",
    "print('Test Set Pixel Accuracy', np.mean(mob_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
